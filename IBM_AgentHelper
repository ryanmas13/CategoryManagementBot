# Setup the LLM
import streamlit as st
from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods
from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes
from langchain_ibm import WatsonxLLM

apikey = st.secrets.IBM.API_KEY
url = st.secrets.IBM.URL

from ibm_watsonx_ai import Credentials

credentials = Credentials(
    url = url,
    api_key = apikey
)

try:
    projectID = st.secrets.IBM.PROJECT_ID
except KeyError:
    projectID = st.text_input("Couldn't find project ID to run this project. Please contact the developer")

from ibm_watsonx_ai import APIClient
WatsonXAI = APIClient(credentials, projectID)

def LLM():

    model_id = ModelTypes.GRANITE_13B_CHAT_V2
    
    parameters = {
        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,
        GenParams.MIN_NEW_TOKENS: 1,
        GenParams.MAX_NEW_TOKENS: 100,
        GenParams.STOP_SEQUENCES: ["<|endoftext|>"]
    }
    
    watsonx_Granite = WatsonxLLM(
    model_id=model_id.value,
    url=credentials.get("url"),
    apikey=credentials.get("apikey"),
    project_id=projectID,
    params=parameters
)